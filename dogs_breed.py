# -*- coding: utf-8 -*-
"""dogs_breed.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JL-Sgv_tP-qLn-Fmr4fJAuWgltgv8lfM
"""

# Importing TensorFlow and TensorFlow Hub
import tensorflow as tf
import tensorflow_hub as hub
print("TF version is : ", tf.__version__)
print("TF Hub version is : ", hub.__version__)

# Make sur we're using a GPU
if tf.config.list_physical_devices("GPU"):
  print('GPU Used')

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# Parameters
img_size = 224
batch_size = 32
num_classes = 9

# Load Data
train_dir = "/content/drive/MyDrive/dog breed/project/train"
valid_dir = "/content/drive/MyDrive/dog breed/project/valid"
test_dir = "/content/drive/MyDrive/dog breed/project/test"

# Data augmentation for training
train_gen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    zoom_range=0.2,
    horizontal_flip=True,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.15
)

valid_gen = ImageDataGenerator(rescale=1./255)
test_gen = ImageDataGenerator(rescale=1./255)

train_data = train_gen.flow_from_directory(train_dir, target_size=(img_size, img_size), batch_size=batch_size, class_mode='categorical')
valid_data = valid_gen.flow_from_directory(valid_dir, target_size=(img_size, img_size), batch_size=batch_size, class_mode='categorical')
test_data = test_gen.flow_from_directory(test_dir, target_size=(img_size, img_size), batch_size=batch_size, class_mode='categorical')

# Build Model
base_model = MobileNetV2(input_shape=(img_size, img_size, 3), include_top=False, weights='imagenet')
base_model.trainable = False  # Freeze base initially

model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(num_classes, activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Callbacks
callbacks = [
    EarlyStopping(patience=3, restore_best_weights=True),
    ModelCheckpoint("best_model.h5", save_best_only=True)
]

# Train top layers
initial_epochs = 10
history = model.fit(train_data, validation_data=valid_data, epochs=initial_epochs, callbacks=callbacks)

# Fine-tuning
base_model.trainable = True
model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])
fine_tune_epochs = 10

total_epochs = initial_epochs + fine_tune_epochs
history_fine = model.fit(train_data, validation_data=valid_data, epochs=total_epochs, initial_epoch=initial_epochs, callbacks=callbacks)

# Evaluate
test_loss, test_acc = model.evaluate(test_data)
print(f"Test Accuracy: {test_acc:.2f}")

test_loss, test_acc = model.evaluate(test_data)
print(f"Test Accuracy: {test_acc:.2f}")
print(f"Test Loss: {test_loss:.2f}")

model.save("dog_classifier_model.h5")

from tensorflow.keras.preprocessing import image
import numpy as np

# Load and preprocess the image
img_path = "/content/drive/MyDrive/dog breed/project/test/Pit Bull/05.jpg"
img = image.load_img(img_path, target_size=(224, 224))  # Resize to match model input
img_array = image.img_to_array(img) / 255.0              # Normalize pixel values
img_array = np.expand_dims(img_array, axis=0)            # Add batch dimension

# Predict
pred_probs = model.predict(img_array)
pred_class_index = np.argmax(pred_probs)
class_names = list(train_data.class_indices.keys())      # Same order used in training
predicted_class = class_names[pred_class_index]

print(f"Predicted class: {predicted_class}")

import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Get true labels
true_labels = test_data.classes
class_names = list(test_data.class_indices.keys())

# Predict
pred_probs = model.predict(test_data)
pred_labels = np.argmax(pred_probs, axis=1)

# Confusion matrix
cm = confusion_matrix(true_labels, pred_labels)

# Plot confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Classification report
print(classification_report(true_labels, pred_labels, target_names=class_names))